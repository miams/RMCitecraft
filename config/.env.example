# RMCitecraft Configuration
# Copy this file to .env and fill in your values

# UI Mode
# Set to true for native desktop window, false for browser mode (better for development)
RMCITECRAFT_NATIVE=false

# LLM Provider Settings
# Options: anthropic, openai, ollama
DEFAULT_LLM_PROVIDER=anthropic
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=1024

# Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-xxxxx
ANTHROPIC_MODEL=claude-3-5-sonnet-20250110

# OpenAI (GPT-4)
OPENAI_API_KEY=sk-xxxxx
OPENAI_MODEL=gpt-4-turbo-preview

# Ollama (local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Database
RM_DATABASE_PATH=data/Iiams.rmtree

# SQLite Extension
SQLITE_ICU_EXTENSION=./sqlite-extension/icu.dylib

# Output Settings
OUTPUT_DIR=output
EXPORT_DIR=exports

# Logging
LOG_LEVEL=INFO
LOG_FILE=rmcitecraft.log
LLM_DEBUG_LOG_FILE=logs/llm_debug.jsonl
