# RMCitecraft Configuration
# Copy this file to .env and fill in your values

# UI Mode
# Set to true for native desktop window, false for browser mode (better for development)
RMCITECRAFT_NATIVE=false

# LLM Provider Settings
# Options: llm (Datasette), openrouter, anthropic, openai, ollama
DEFAULT_LLM_PROVIDER=openrouter
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=1024

# LLM (Datasette) - Local CLI tool
# Note: Configure API keys using: llm keys set openai
# No configuration needed here, just set DEFAULT_LLM_PROVIDER=llm

# OpenRouter - Multi-model gateway
OPENROUTER_API_KEY=sk-or-xxxxx
OPENROUTER_SITE_URL=https://rmcitecraft.app
OPENROUTER_APP_NAME=RMCitecraft

# Default models for specific tasks
PHOTO_CLASSIFICATION_MODEL=anthropic/claude-3-haiku
CENSUS_TRANSCRIPTION_MODEL=openai/gpt-4-vision-preview

# Legacy providers (for citation parsing)
# Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-xxxxx
ANTHROPIC_MODEL=claude-3-5-sonnet-20250110

# OpenAI (GPT-4)
OPENAI_API_KEY=sk-xxxxx
OPENAI_MODEL=gpt-4-turbo-preview

# Ollama (local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Database
RM_DATABASE_PATH=data/Iiams.rmtree

# SQLite Extension
SQLITE_ICU_EXTENSION=./sqlite-extension/icu.dylib

# Output Settings
OUTPUT_DIR=output
EXPORT_DIR=exports

# Logging
LOG_LEVEL=INFO
LOG_FILE=rmcitecraft.log
LLM_DEBUG_LOG_FILE=logs/llm_debug.jsonl
